{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1173b32f",
   "metadata": {},
   "source": [
    "# 导入包和函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de55386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import rpy2.robjects as robjects\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "torch.manual_seed(756)\n",
    "np.random.seed(756)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from mfdnn import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ad16e",
   "metadata": {},
   "source": [
    "# 基础设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaaff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(756)\n",
    "np.random.seed(756)\n",
    "\n",
    "\n",
    "data_path = \"EEG\"\n",
    "\n",
    "train_indices_list = pd.read_csv(os.path.join(data_path, \"train_indices_list.csv\"))\n",
    "test_indices_list  = pd.read_csv(os.path.join(data_path, \"test_indices_list.csv\"))\n",
    "\n",
    "rds_file = os.path.join(data_path, \"EEG_y.rds\")\n",
    "r_array = robjects.r['readRDS'](rds_file)\n",
    "\n",
    "EEG_x = np.array(r_array)  # 64*64*61\n",
    "EEG_y = np.array([1]*39 + [-1]*22)  \n",
    "\n",
    "\n",
    "n = 61           \n",
    "p = 1              \n",
    "frun = 50           \n",
    "\n",
    "domain_range=[np.array([0, 1]), np.array([1, 64])]\n",
    "\n",
    "model_params = {\n",
    "    'num_basis': [5, 5],        \n",
    "    'layer_sizes': [64, 64],    \n",
    "    'epochs': 200,             \n",
    "    'val_ratio': 0.1,           \n",
    "    'patience': 10             \n",
    "}\n",
    "\n",
    "\n",
    "lam1_values = [0.01, 0.05, 0.1, 0.5, 1, 2, 5]\n",
    "lam2_values = [0, 0.001, 0.01, 0.1, 1, 2, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a4dd0e",
   "metadata": {},
   "source": [
    "# 回归神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42029d7d",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_hyperparameters(\n",
    "    X_train, y_train, p, domain_range,\n",
    "    lam1_values, lam2_values, model_params\n",
    "):\n",
    "\n",
    "\n",
    "    mse_results = np.zeros((len(lam1_values), len(lam2_values)))\n",
    "    model_info = {}\n",
    "\n",
    "    for i, lam1 in enumerate(lam1_values):\n",
    "        for j, lam2 in enumerate(lam2_values):\n",
    "            try:\n",
    "                train_losses, val_losses, model, _ = MFDNN(\n",
    "                    p=p, resp=y_train, func_cov=X_train,\n",
    "                    num_basis=model_params['num_basis'],\n",
    "                    layer_sizes=model_params['layer_sizes'],\n",
    "                    domain_range=domain_range,\n",
    "                    epochs=model_params['epochs'],\n",
    "                    val_ratio=model_params['val_ratio'],\n",
    "                    patience=model_params['patience'],\n",
    "                    lam1=lam1, lam2=lam2,\n",
    "                    std_resp=True\n",
    "                )\n",
    "\n",
    "                mse = min(val_losses) if len(val_losses) > 0 else np.mean(train_losses[-10:])\n",
    "                mse_results[i, j] = mse\n",
    "\n",
    "                model_info[f\"{i}_{j}\"] = model\n",
    "\n",
    "            except Exception as e:\n",
    "                mse_results[i, j] = np.inf\n",
    "                model_info[f\"{i}_{j}\"] = None\n",
    "\n",
    "    best_idx = np.unravel_index(np.argmin(mse_results), mse_results.shape)\n",
    "    best_lam1 = lam1_values[best_idx[0]]\n",
    "    best_lam2 = lam2_values[best_idx[1]]\n",
    "    best_model = model_info[f\"{best_idx[0]}_{best_idx[1]}\"]\n",
    "\n",
    "    return best_lam1, best_lam2, best_model\n",
    "\n",
    "def evaluate_on_test_set(best_model, X_test, y_test, p, domain_range, model_params):\n",
    "\n",
    "    try:\n",
    "        test_predictions = MFDNN_predict(\n",
    "            p, best_model, X_test, model_params['num_basis'], domain_range\n",
    "        ).detach().numpy()  \n",
    "        \n",
    "        test_labels = np.where(test_predictions.flatten() > 0, 1, -1)\n",
    "\n",
    "        f1 = f1_score(y_test, test_labels, pos_label=1)\n",
    "        \n",
    "        return f1, test_labels\n",
    "    except Exception as e:\n",
    "        return 0.0, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537b88d",
   "metadata": {},
   "source": [
    "## 回归50次循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01733a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/50\n",
      "Run 2/50\n",
      "Run 3/50\n",
      "Run 4/50\n",
      "Run 5/50\n",
      "Run 6/50\n",
      "Run 7/50\n",
      "Run 8/50\n",
      "Run 9/50\n",
      "Run 10/50\n",
      "Run 11/50\n",
      "Run 12/50\n",
      "Run 13/50\n",
      "Run 14/50\n",
      "Run 15/50\n",
      "Run 16/50\n",
      "Run 17/50\n",
      "Run 18/50\n",
      "Run 19/50\n",
      "Run 20/50\n",
      "Run 21/50\n",
      "Run 22/50\n",
      "Run 23/50\n",
      "Run 24/50\n",
      "Run 25/50\n",
      "Run 26/50\n",
      "Run 27/50\n",
      "Run 28/50\n",
      "Run 29/50\n",
      "Run 30/50\n",
      "Run 31/50\n",
      "Run 32/50\n",
      "Run 33/50\n",
      "Run 34/50\n",
      "Run 35/50\n",
      "Run 36/50\n",
      "Run 37/50\n",
      "Run 38/50\n",
      "Run 39/50\n",
      "Run 40/50\n",
      "Run 41/50\n",
      "Run 42/50\n",
      "Run 43/50\n",
      "Run 44/50\n",
      "Run 45/50\n",
      "Run 46/50\n",
      "Run 47/50\n",
      "Run 48/50\n",
      "Run 49/50\n",
      "Run 50/50\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(756)\n",
    "np.random.seed(756)\n",
    "\n",
    "all_f1 = []\n",
    "all_best_lam1 = []\n",
    "all_best_lam2 = []\n",
    "\n",
    "for run_idx in range(frun):\n",
    "    print(f\"Run {run_idx+1}/{frun}\")\n",
    "\n",
    "    train_indices = train_indices_list.iloc[:, run_idx].to_numpy() - 1\n",
    "    test_indices  = test_indices_list.iloc[:, run_idx].to_numpy() - 1\n",
    "\n",
    "    X_train = np.transpose(EEG_x[:, :, train_indices], (2, 0, 1))\n",
    "    X_test  = np.transpose(EEG_x[:, :, test_indices], (2, 0, 1))\n",
    "    y_train = EEG_y[train_indices]\n",
    "    y_test  = EEG_y[test_indices]\n",
    "\n",
    "    best_lam1, best_lam2, best_model = select_best_hyperparameters(\n",
    "        X_train, y_train, p, domain_range, lam1_values, lam2_values, model_params\n",
    "    )\n",
    "\n",
    "    f1, _ = evaluate_on_test_set(\n",
    "        best_model, X_test, y_test, p, domain_range, model_params\n",
    "    )\n",
    "    \n",
    "    all_f1.append(f1)\n",
    "    all_best_lam1.append(best_lam1)\n",
    "    all_best_lam2.append(best_lam2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83322114",
   "metadata": {},
   "source": [
    "## 回归输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eca656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均 F1-score: 0.7485, 标准差: 0.1004\n",
      "结果已保存到文件: EEG_MFDNN_F1_results.csv\n"
     ]
    }
   ],
   "source": [
    "mean_f1 = np.mean(all_f1)\n",
    "std_f1 = np.std(all_f1)\n",
    "\n",
    "filename = f\"EEG_MFDNN_F1_results.csv\"\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"mean_f1\": [mean_f1],\n",
    "    \"std_f1\": [std_f1]\n",
    "})\n",
    "\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193df71f",
   "metadata": {},
   "source": [
    "# 分类神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc5a26",
   "metadata": {},
   "source": [
    "## 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "torch.manual_seed(756)\n",
    "np.random.seed(756)\n",
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes):\n",
    "        super(ClassificationNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        self.input = nn.Linear(input_size, hidden_layer_sizes[0])\n",
    "        layers.append(self.input)\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for i in range(len(hidden_layer_sizes) - 1):\n",
    "            layers.append(nn.Linear(hidden_layer_sizes[i], hidden_layer_sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_layer_sizes[-1], 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.model(x)\n",
    "\n",
    "    @property\n",
    "    def input_weight(self):\n",
    "        return self.input.weight\n",
    "\n",
    "def MFDNN_calssification(p, resp, func_cov, num_basis, layer_sizes, domain_range, epochs, val_ratio, patience, lam1=0, lam2=0, epsilon=0.001, std_resp=True):  \n",
    "    \"\"\"\n",
    "    Multi-dimensional Functional Deep Neural Network (MFDNN) training function - supports only 2D functional data.\n",
    "\n",
    "    Parameters:\n",
    "        p (int): Number of functional variables.\n",
    "        resp (numpy.ndarray): Response variable.\n",
    "        func_cov (numpy.ndarray): Functional covariate data with shape:\n",
    "            - If p=1: (N, T1, T2)\n",
    "            - If p>1: (p, N, T1, T2)\n",
    "        num_basis (tuple): Number of basis functions for each dimension (M1, M2).\n",
    "        layer_sizes (list): Number of neurons in each hidden layer of the neural network.\n",
    "        domain_range (list): List of p elements, each being [lower_bound, upper_bound].\n",
    "        epochs (int): Number of training epochs.\n",
    "        val_ratio (float, optional): Validation set ratio. Defaults to None.\n",
    "        patience (int, optional): Early stopping patience. Defaults to None.\n",
    "        lam (float, optional): Regularization parameter. Defaults to 0.\n",
    "        epsilon (float, optional): Minimum change for early stopping. Defaults to 0.001.\n",
    "        std_resp (bool, optional): Whether to standardize response variable. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_losses, validation_losses, model, l21_norm)\n",
    "            - train_losses (list): Training loss values.\n",
    "            - validation_losses (list): Validation loss values (if val_ratio is not None).\n",
    "            - model (RegressionNN): Trained neural network model.\n",
    "            - l21_norm (torch.Tensor): L21 normalization coefficients for variable selection.\n",
    "    \"\"\"\n",
    "    # Process 2D functional data using optimized integral function\n",
    "    A = integral(func_cov, num_basis, domain_range)  # Shape: (N, p, M1*M2) or (N, M1*M2)\n",
    "    S = smooth_penalty(func_cov, num_basis, domain_range)\n",
    "    S = torch.tensor(S, dtype=torch.float32)\n",
    "    N = A.shape[0]\n",
    "\n",
    "    # Calculate input feature dimension\n",
    "    if len(A.shape) == 2:  # p=1 case\n",
    "        M = A.shape[1]\n",
    "        input_size = M\n",
    "    else:  # p>1 case\n",
    "        M = A.shape[2]\n",
    "        input_size = p * M\n",
    "\n",
    "    # Dataset splitting and preprocessing\n",
    "    if val_ratio is not None:\n",
    "        trainX, validationX, trainy, validationy = train_test_split(A, resp, test_size=val_ratio, random_state=42)\n",
    "        trainX = torch.Tensor(trainX).float()\n",
    "        trainy = torch.Tensor(trainy).view(-1, 1).float()\n",
    "        validationX = torch.Tensor(validationX).float()\n",
    "        validationy = torch.Tensor(validationy).view(-1, 1).float()\n",
    "\n",
    "        if std_resp:\n",
    "            trainy = (trainy - torch.mean(trainy)) / torch.std(trainy)\n",
    "            validationy = (validationy - torch.mean(validationy)) / torch.std(validationy)\n",
    "    else:\n",
    "        trainX = torch.Tensor(A).float()\n",
    "        trainy = torch.Tensor(resp).view(N, 1).float()\n",
    "        if std_resp:\n",
    "            trainy = (trainy - torch.mean(trainy)) / torch.std(trainy)\n",
    "    \n",
    "    # Create and train model\n",
    "    model = ClassificationNN(input_size, layer_sizes)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # 分类损失\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  \n",
    "    \n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    if patience is not None:\n",
    "        best_val_loss = float('inf')\n",
    "        stopping_patience = patience\n",
    "    \n",
    "    # Training loop\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(trainX)\n",
    "        loss = criterion(outputs, trainy)\n",
    "        \n",
    "        if lam1 == 0 or p == 1:\n",
    "            weight = model.input_weight  # shape: (n1, p * M)\n",
    "            norm = torch.sum((weight @ S) * weight, dim=1)\n",
    "            regularization = lam2 * torch.mean(norm)\n",
    "            total_loss = loss + regularization\n",
    "            total_loss.backward()\n",
    "        else:\n",
    "            weight = model.input_weight  # shape: (n1, p * M)\n",
    "            norm1 = torch.sum(weight ** 2, dim=0).view(p, M).sum(dim=1) # p * 1\n",
    "            norm2 = torch.sum((weight @ S) * weight, dim=1)\n",
    "            regularization1 = lam1 * torch.sum(torch.sqrt(norm1 + 1e-6))\n",
    "            regularization2 = lam2 * torch.mean(norm2)\n",
    "            total_loss = loss + regularization1 + regularization2\n",
    "            total_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # Early stopping check\n",
    "        if patience is not None:\n",
    "            val_loss = criterion(model(validationX), validationy)\n",
    "            validation_losses.append(val_loss.item())\n",
    "            \n",
    "            if val_loss < best_val_loss and best_val_loss - val_loss >= epsilon:\n",
    "                best_val_loss = val_loss\n",
    "                stopping_patience = patience\n",
    "            else:\n",
    "                stopping_patience -= 1\n",
    "                if stopping_patience == 0:\n",
    "                    break\n",
    "    \n",
    "    # Calculate L21 norm for variable selection\n",
    "    if p == 1:\n",
    "        l21_norm = torch.sqrt(torch.sum(model.input_weight ** 2, dim=0))\n",
    "    else:\n",
    "        l21_norm = torch.sqrt(torch.sum(model.input_weight ** 2, dim=0).view(p, M).sum(dim=1))\n",
    "    \n",
    "    \n",
    "    return train_losses, validation_losses, model, l21_norm\n",
    "\n",
    "def MFDNN_predict_classification(p, model, func_cov, num_basis, domain_range):\n",
    "    \"\"\"\n",
    "    Predict using trained MFDNN model - supports only 2D functional data.\n",
    "\n",
    "    Parameters:\n",
    "        p (int): Number of functional variables.\n",
    "        model (RegressionNN): Trained MFDNN model.\n",
    "        func_cov (numpy.ndarray): Functional covariate data for test set with shape:\n",
    "            - If p=1: (N, T1, T2)\n",
    "            - If p>1: (p, N, T1, T2)\n",
    "        num_basis (tuple): Number of basis functions for each dimension (M1, M2).\n",
    "        domain_range (list): List of p elements, each being [lower_bound, upper_bound].\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Predicted values.\n",
    "    \"\"\"\n",
    "    # Process 2D functional data using optimized integral function\n",
    "    A = integral(func_cov, num_basis, domain_range)\n",
    "    testX = torch.Tensor(A).float()\n",
    "    logits = model(testX)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0375f",
   "metadata": {},
   "source": [
    "## 分类50次循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/50\n",
      "Run 2/50\n",
      "Run 3/50\n",
      "Run 4/50\n",
      "Run 5/50\n",
      "Run 6/50\n",
      "Run 7/50\n",
      "Run 8/50\n",
      "Run 9/50\n",
      "Run 10/50\n",
      "Run 11/50\n",
      "Run 12/50\n",
      "Run 13/50\n",
      "Run 14/50\n",
      "Run 15/50\n",
      "Run 16/50\n",
      "Run 17/50\n",
      "Run 18/50\n",
      "Run 19/50\n",
      "Run 20/50\n",
      "Run 21/50\n",
      "Run 22/50\n",
      "Run 23/50\n",
      "Run 24/50\n",
      "Run 25/50\n",
      "Run 26/50\n",
      "Run 27/50\n",
      "Run 28/50\n",
      "Run 29/50\n",
      "Run 30/50\n",
      "Run 31/50\n",
      "Run 32/50\n",
      "Run 33/50\n",
      "Run 34/50\n",
      "Run 35/50\n",
      "Run 36/50\n",
      "Run 37/50\n",
      "Run 38/50\n",
      "Run 39/50\n",
      "Run 40/50\n",
      "Run 41/50\n",
      "Run 42/50\n",
      "Run 43/50\n",
      "Run 44/50\n",
      "Run 45/50\n",
      "Run 46/50\n",
      "Run 47/50\n",
      "Run 48/50\n",
      "Run 49/50\n",
      "Run 50/50\n",
      "平均 F1-score: 0.7485, 标准差: 0.1004\n"
     ]
    }
   ],
   "source": [
    "all_f1 = []\n",
    "all_best_lam1 = []\n",
    "all_best_lam2 = []\n",
    "\n",
    "for run_idx in range(frun):\n",
    "    print(f\"Run {run_idx+1}/{frun}\")\n",
    "\n",
    "    train_indices = train_indices_list.iloc[:, run_idx].to_numpy() - 1\n",
    "    test_indices  = test_indices_list.iloc[:, run_idx].to_numpy() - 1\n",
    "\n",
    "    X_train = np.transpose(EEG_x[:, :, train_indices], (2, 0, 1))\n",
    "    X_test  = np.transpose(EEG_x[:, :, test_indices], (2, 0, 1))\n",
    "    y_train = EEG_y[train_indices]\n",
    "    y_test  = EEG_y[test_indices]\n",
    "\n",
    "    best_lam1, best_lam2, best_model = select_best_hyperparameters(\n",
    "        X_train, y_train, p, domain_range, lam1_values, lam2_values, model_params\n",
    "    )\n",
    "\n",
    "    logits = MFDNN_predict_classification(p, best_model, X_test, model_params['num_basis'], domain_range)\n",
    "    y_pred = torch.where(logits.flatten() > 0, 1, -1).numpy()  \n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "    all_f1.append(f1)\n",
    "    all_best_lam1.append(best_lam1)\n",
    "    all_best_lam2.append(best_lam2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d34401",
   "metadata": {},
   "source": [
    "## 分类输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均 F1-score: 0.7555, 标准差: 0.0879\n",
      "结果已保存到文件: EEG_MFDNN_calssification_F1_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_f1 = np.mean(all_f1)\n",
    "std_f1 = np.std(all_f1)\n",
    "\n",
    "filename = f\"EEG_MFDNN_calssification_F1_results.csv\"\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"mean_f1\": [mean_f1],\n",
    "    \"std_f1\": [std_f1]\n",
    "})\n",
    "\n",
    "df.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
